讨论 2021-01-07
=

# 经典模型及算法导览 （七）
## 弱监督学习：从distant learning到PU learning

### 取之不尽的数据
目前深度学习高度依赖于数据，而高质量的标注数据往往需要高昂的成本，数据规模十分受限。所以研究者们放眼于一种新的数据获取方式，即通过一定规则和知识，自动的收集数据。这种方法可以廉价地，大量地收集数据，但随之而来的问题也十分明显，数据的标注可能有误，并且采集到的数据分布可能与真实数据分布不一致。

### distant learning
不同于无监督学习中随意抓取数据，distant learning通常需要人为提供的一些知识，比如在知识抽取领域中的著名假设，假设一句话中出现了两个特定的实体，这句话大概率体现了他们之间的关系。即给定三元组 (e1,r,e2)，如果一句话包含e1,e2，则一定体现了r。

|Relation name |Size |Example|
|-|-|-|
|/people/person/nationality |281,107 |John Dugard, South Africa|
|/location/location/contains| 253,223| Belgium, Nijlen|
|/people/person/profession| 208,888| Dusa McDuff, Mathematician|
|/people/person/place of birth |105,799| Edwin Hubble, Marshfield|
|/dining/restaurant/cuisine |86,213| MacAyo’s Mexican Kitchen, Mexican|
|/business/business chain/location |66,529| Apple Inc., Apple Inc., South Park, NC|

又或者在NER，entity linking等任务中，我们通过字典筛选出一部分数据，这些标注很大概率是有缺失的，比如只能找到一些有名的地方和人物，但知名度较低的就会错过。

这也就引出了两个问题
- 数据标注有噪声
- 数据标注有缺失

这两个问题分别对应了 Learning with noise 和 Positive-Unlabeled Learning  两个方向。

### Learning with noise
首先我们要理解一个问题是什么是噪声抗性。它的定义是无噪声情况的最优解一定是有噪声情况下的最优解。也就是我们通过学习有噪声的样本可以找到无噪声的最优解，这是至关重要的性质，否则我们是在求解优化另一问题，而不是原问题。
函数f在loss L下的风险为$$R_L(f) = E_{x,y^*} L(f(x), y^*)$$
另外噪声概率为n，共k类
假设有$$\sum_i^k L(f(x),i)=C$$,C为常数
\begin{align}
R^n_L(f) =& E_{x,y} L(f(x), y) \\
=& \sum_x \sum_y P(x,y) L(f(x), y) \\
=& \sum_x \sum_y \sum_{y^*} P(x,y,y^*) L(f(x),y)\\
=& \sum_x \sum_y \sum_{y^*} P(x) P(y^*|x) P(y|x,y^*) L(f(x),y) \\
=& \sum_x \sum_{y^*} P(x) P(y^*|x) [(1-n) L(f(x),y^*) + \frac{n}{k-1} \sum_{i,i\neq y*} L(f(x),i)] \\
=& \sum_{x,y^*} P(x,y^*) [(1-n) L(f(x),y^*) + \frac{n}{k-1} \sum_{i,i\neq y*} L(f(x),i)] \\
=& (1-n) R_L(f) + \frac{n}{k-1} (C-R_L(f)) \\
=& \frac{Cn}{k-1} + (1-\frac{nk}{k-1}) R_L(f) \\
\end{align}

那么无噪声的最优解$f^*$和任意解$f$在噪声数据上有
$$R^n_L(f^*)-R^n_L(f) = (1-\frac{nk}{k-1})(R_L(f^*)-R_L(f)) $$
所以$n<\frac{k-1}{k}$时，上式小于等于0，即无噪声最优解还是噪声数据上的最优解。

总loss为常数这一设定其实很好满足，对任意loss进行归一化即可，但原始的cross entropy不满足。

大家也可以尝试用CE推导，其他工作有提及CE是不能保证有噪声抗性的，即不一定满足无噪声最优还是有噪声最优。

不过，抗噪声的loss经常学习效率不高，一种最近提出的解释是这类loss通常可以再只少量提高或不提高正确类别置信的情况下减小一定量的loss


### Positive-Unlabeled Learning
PU learning 有很多不同的方法和思路，同时也会借助各种各样的假设。这里只提及一种比较简单的方法，同时其假设是事先知道正负样本的比例。假设正负比例为$\pi_p : \pi_n$，我们可以把具有正负类样本的经验风险$R_{pn}$改写成只有正样本的经验风险$R_{pu}$，从而得到正确的loss形式。
\begin{gather}
R^-_p(f) = E_{x_p} L(f(x_p), -1) \\
R^+_p(f) = E_{x_p} L(f(x_p), 1) \\
R_{pn}(f) = \pi_p R^+_p(f) + \pi_n R^-_n(f) \\
\pi_n p_n (x) = p(x)-\pi_p p_p(x) \\
R_{pu} = \pi_p R^+_p (f)- \pi_p R^-_p(f) + R^-_u(f) 
\end{gather}

### 小结
如果样本噪声强度不高，可以采用learning with noise的方法，如果噪声强度实在太高，可以退化为PU learning问题。这两者本质是都是不可解的问题，所以一定需要某种程度上的假设，对数据本身的理解和估计才是根本问题，如果在数据上采用了不合适的假设，效果必然有限。
