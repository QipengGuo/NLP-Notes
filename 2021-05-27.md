讨论2021-05-27
=

# Pre-training 第三讲

# 预训练的局限和机遇
预训练模型发展的如火如荼，受到了大量的关注，也提供了非常多的科研机会。但其中一些关键的基本问题还尚未得到很好地解决。

## BERT到底会什么？不会什么？
以BERT为代表的预训练模型在众多任务上取得了优异的成绩，但BERT本身掌握了哪些知识还有待探索。已有不少工作聚焦于这一点，他们对BERT的各项特点进行了分析和探究，总结出了很多有价值的观点，其中典型的有以下几点：

### 字面信息

有一些经典的测试任务来检测一个模型对于语言现象的敏感程度，类似于unit test

Surface Information:
- SentLen: Number of words in a sentence
- WC (Word Content): Presence or absence of a word


Syntactic Information:
- BShift (Bigram Shift): Sensitivity to legal word orders – i.e. swapping adjacent words
- TreeDepth: Depth of hierarchical relationships in the sentence – longest path from node to leaf
- TopConst (Top Constituents): Classify top constituents below root node

Semantic Information:
- Tense: Tense of main-clause verb
- SubjNum (Subject Number): Number of the subject of the main clause
- ObjNum (Object Number): Number of the object of the main clause
- SOMO (Semantic Odd-Man-Out): Replace a random noun or verb with another that has comparable bigram frequency
- CoordInv (Coordinate Inversion): Invert order of clauses in sentences containing two coordinate clauses. “They might be only memories, but I can still feel each one” -> “I can still feel each one, but they might only be memories”

![](https://i.imgur.com/EQKclki.png)

![](https://i.imgur.com/TPGiPIO.png)

可以看出，BERT尽在 Bshift 和 CoordInv两个测试中优于之前的方法，但需要注意的是BERT的综合实力很强并且是无监督的。同时，我们应该从几个方面看这些提高，首先WC和BShift这类提高和Attention机制应该关系不大，更多是来源是大规模训练数据和模型参数量。而CoordInv则是典型的需要长距离信息，这点上Transformer结构确实有它的优越性。

 https://www.aclweb.org/anthology/2020.tacl-1.54.pdf
 
## 不完整的Syntax

一些工作指出BERT不理解否定词的用法，对齐否定的范围和一图不能正确理解。同时BERT理解的Syntax结构似乎比语言学家认为的要浅，或者BERT还不能掌握深层嵌套结构。另一些工作也同步指出了BERT对指代关系理解不完整的问题。

## 缺失的语义

BERT对主谓宾等语义角色有一定了解，对人名、地点有一定知识，但其对数字表现很差，并且对NER是死记硬背，简单的专有名词替换就很可能改变BERT的理解。

## 几乎没有推理

很多工作都指出了BERT几乎没有推理能力，不能回答应用题，只能回答事实性问题，不能很好的接纳和运用新知识。比如能回答对人能走进房子，也能回答出体积大的物体能容纳体积小的物体，但确不知道人比房子小。


![](https://i.imgur.com/X9eDMm2.png)
## 一些治标的问题
- 长文本预训练还不成熟
- Attention冗余过多（head的模式同质化、很多Attention都是汇总到cls或sep）
- 更好的结合语言特点

## 对基本假设的质疑

语言模型或者说估计$P(x)$的预训练方法真的能够学到足够多的知识吗？

目前主流观点是存在一个自然语言空间，我们收集到的文本都满足i.i.d.采样，但这种观点可能存在一些问题，语言本身随时间、地域、民俗、各种人类社会的事件而变化。现有的采样方式很可能会引入外部因素（即语言之外的因素），这很有可能导致巨大的训练集也不能让我们对$P(x)$建模的更好，或者说陷入瓶颈期，因为采样和假设导致的系统性风险远大于数据集给出的经验风险时，模型的学习效率会变得极低。

另一方面，人们对语言的建模程度很可能没有我们想象的那么好，我们通常以语义一致作为标准而非字面一致。我在转达别人的消息时，很容易做到语义一致，但经常无法做到字面一致，即逐字逐句复述。而语言模型追求的字面一致可能过于偏激。

由此，可能一种模拟信息交流过程的，有两个模型参与的预训练模型会更为有意义。
