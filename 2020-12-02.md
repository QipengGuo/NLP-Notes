讨论 2020-12-02
=

# 经典模型及算法导览 （四）
## Meta Learning 浅谈
Meta Learning 本身的概念很大，设计的方法和工作也很多，这里只做一些简单的探讨，狭义地理解meta learning，主要讨论
Model-Agnostic Meta-Learning (MAML)相关的方法。

网上教程很多，可参考
https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html
https://www.facebook.com/icml.imls/videos/400619163874853/

### Meta Learning的目标是什么？
比较通俗的解释的是，如果一般的学习任务是找到解决实际问题的方法，那meta-learning的目标是找到一套好的学习方法，也就是我们从小听到大的辅导班广告语，好的学习方法可以让我们成绩提高，花的时间还少。但需要指出的是，实际上大部分meta-learning的方法都比这一解释要局限的多，说他们是在寻找最好的学习方法通常是不准确的。

以MAML为例，他实际上是寻找最好迁移的网络初始化参数，问题定义比我们上面说的找学习方法要小很多，其他方法也类似。

另一个比较含糊的问题是，meta-learning是不是需要涉及泛化性，或者是否要考量在多个数据集上的表现。这个问题其实不太好回答，MAML相关的，以及很多meta-learning的方法都把多个数据集写入了他们的问题定义，但有一些工作，比如可学习的优化器（learning to learn）就是只考虑一个数据集的。

上述内容有些抽象，下面我们主要介绍两个工作

### Learning to learn by gradient descent by gradient descent
Learning to learn 的 motivation非常直白，在我们训练一个神经网的时候都会用优化器，比如SGD，Adam，RMSprop等，那么优化器本身可不可以学习？这系列的工作就是要学习一个好的优化器（通常是一个以gradient为输入的小网络），学习一个好的优化器和我们说的找到一个好的学习方法非常相关，我个人也认为这个系列是很符合meta-learning精神的。

稍微具体些,参数的更新过程通常为

\begin{align}
\theta_{t+1} = \theta_t -\alpha \nabla L(D;\theta_t),
\end{align}
$D$是数据，$\alpha$是学习率，$L$是误差函数，$\theta$是参数
而Learning to learn把这个流程修改为
\begin{align}
\theta_{t+1} = \theta_t -\alpha g(\nabla L(D;\theta_t);\phi),
\end{align}
这里$g$和$\phi$就是要学习的优化器和它的参数。
其实这类方法的思路就是这么简单，剩下的问题就是如何设计这个函数$g$,这里只做大概的介绍，就是用一个LSTM来接受每一步的gradient，然后再生成真正的更新量。另外这里通常会做 优化器与被优化参数无关的假设，即优化器不应该随网络参数不同而采取不同策略。这样可以减少高阶导的计算。当然，这类的工作trick很多，感兴趣的同学可以研究。
![](https://i.imgur.com/Z2k5EFW.png)


### Model-Agnostic Meta-Learning (MAML)
MAML的思想就是让以目前参数初始化，finetune之后的模型表现最优。换言之，不是让模型当前状态最好，而是让模型走两步之后效果最好。
![](https://i.imgur.com/Qc1Pz2t.png)


这类算法基本都采用二级结构，内层模拟在每个任务上学习，外层负责更新meta参数。
![](https://i.imgur.com/fxsuHNB.png)

但是，实际上MAML不是这么用的，通常要结合few-shot的场景
![](https://i.imgur.com/uAGSGJH.png)

那么MAML怎么变到这一步的呢？实际上从MAML本身过不来。。。 需要另一篇文章，https://arxiv.org/pdf/1606.04080.pdf


另外，很多时候人们都会采用MAML的一阶近似，即不求二阶导，理论上这样不好，但实际有些时候，只用一阶信息比二阶信息还要好。这其实会牵涉很多方面的原因，一个比较简单的原因就是神经网络对修改量比较敏感，通常不能承受很大的修改量，而二阶项会比一阶项更难以控制，更容易爆炸或弥散。
