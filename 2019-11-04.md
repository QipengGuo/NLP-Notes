讨论 2019-11-04
=

# 机器翻译中的冷门任务及衍生任务

## 模型改进
模型改进虽然工作很多，但内容高度分化，具体每个系列的工作并不多。模型改进的工作主要出于两个动机，一是解决应用中遇到的问题，二是完善理论性质。第一类工作主要关注当下热点的问题，比如在翻译时，从左到右再从右到左，或者多种生成顺序混合。这一设计的初衷主要是应对现实问题的，也就是“头疼医头脚疼医脚”。第二类工作则更强调添加或完善了哪些性质，而机器翻译只是验证的舞台，例如对RNN中长时记忆问题的探讨，对Attention中positional embedding的探讨，对Attention本身形式的探讨等。

数据集： 标准的机器翻译数据集
评测： BLEU

## 语言学
与改进模型类似，但重点在于通过引入语言学知识解决问题，通常涉及embedding和额外的tag(syntactic, semantic)。另一方面，大数据往往可以替代先验知识，所以这类工作更常见于小数据和特殊语言对中。

数据集： 偏小，对语言有特殊性
评测： BLEU

## 对齐
由于与Attention机制有很大相似性，所以近年来又重新被重视起来，问题定义十分简洁，希望Attention机制与人类标注的对齐关系尽量一致。很多工作会借助regularization和reinforcement learning来控制Attention的行为。

数据集： 词级别对齐数据
评测： Accuracy

## 评测方法
文本生成任务中的“顽疾”，大量工作阐述了现有评测机制的局限性，但目前仍未有曙光。并且这个任务也与NLP的核心概念十分相关，要想要好的评测方法，必须清晰的建模语义。

数据集： 看设定
评测： 与人类对比

## Exposure Bias
主要指由于teacher forcing导致训练数据分布和测试分布不一致的问题。注意不考虑训练集和测试集的差异，因为假设是独立同分布的。

数据集： 标注的机器翻译数据集
评测： BLEU，通常要看长度对BLEU的影响

## 多模态和特殊场景
近年已经少见，有一部分学术一样不强，但工程需要很大。
比如对image caption的翻译（给定图片），结合语音信号的翻译。特定场合，比如购物，字幕的翻译等。这类工作的baseline通常是没利用额外信息，通用翻译模型的结果。

数据集： 有额外信息的平行语料
评测： BLEU
